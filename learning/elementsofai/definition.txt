In my opinion AI is not "cool things that computers can't do", but "cool things that computers can do". You can see that this definition is old, as the definition probably has changed since then. Where AI was working at things that computers couldn't do, I think a big part of AI research is now more improving the AI model with the increased amount of computing power we have.

In a way machines are imitating intelligent human behavoir. In the beginning we are learning the computer how it should behave with data of humans. But a model can learn from the data and maybe even get better ideas. It starts with imitating human behavior, but it can quickly improve itself. A better definition is: machines begin with imitating intelligent human behavoir, and then improves itself (= adaptivity) by creating a neural network for example.

In my view, autonomy and adaptivity are good words to define AI. They describe the two core activites of AI: performing tasks without constant guidance by a user and improving performance by learning from experience. AI is autonomous, but we gave it data and the task how to work with the data we gave. Adaptivity is a good definition of what AI can do. AI has the power to generate data and check if it is good or not. If it's good it will continue in that direction, if it's bad it will improve itself. 

My own, improved definition of AI is: 'cool' things computers do with data of human beings or with newly generetated data by AI thanks to its autonomy and adaptivity.
In my definition I emphasise the need of human interaction with AI in order to let it work properly. AI needs data from humans in order to do something. We program it, so it can learn from itself and become adaptive. Then it can generate new data to use and learn more and more. In that way it is also autonomous: not much interaction with humans is needed. 
